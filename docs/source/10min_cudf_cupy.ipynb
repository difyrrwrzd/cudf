{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Minutes to cuDF and CuPy\n",
    "\n",
    "This notebook provides introductory examples of how you can use cuDF and CuPy together to take advantage of CuPy array functionality (such as sparse matrix operations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a cuDF Series or DataFrame to a CuPy Array\n",
    "\n",
    "If we want to convert a cuDF `DataFrame` to a CuPy `ndarray`, the best way is to use the `dlpack` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cupy\n",
    "import cudf\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 609 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.7/site-packages/cudf-0.7.1+500.g24ab9736.dirty-py3.7-linux-x86_64.egg/cudf/io/dlpack.py:83: UserWarning: WARNING: cuDF to_dlpack() produces column-major (Fortran order) output. If the output tensor needs to be row major, transpose the output of this function.\n",
      "  return cpp_dlpack.to_dlpack(gdf_cols)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cupy.core.core.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nelem = 10000\n",
    "df = cudf.DataFrame({'a':range(nelem),\n",
    "                     'b':range(500, nelem+500),\n",
    "                     'c':range(1000, nelem+1000)}\n",
    "                   )\n",
    "\n",
    "%time arr_cupy = cupy.fromDlpack(df.to_dlpack())\n",
    "type(arr_cupy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to convert a cuDF `Series` to a CuPy `ndarray` is to either pass the underlying Numba `DeviceNDArray` to `cupy.asarray` or leverage the `dlpack` interface for conversions. We can also pass the `Series` itself, but this will be far slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 405 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 570 µs\n",
      "CPU times: user 2.84 s, sys: 60 ms, total: 2.9 s\n",
      "Wall time: 2.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cupy.core.core.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cola_cupy = cupy.asarray(df['a'].data.mem)\n",
    "%time cola_cupy = cupy.fromDlpack(df['a'].to_dlpack())\n",
    "%time cola_cupy = cupy.asarray(df['a'])\n",
    "type(cola_cupy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can proceed with normal CuPy workflows, such as reshaping the array or getting the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    2, ...,  197,  198,  199],\n",
       "       [ 200,  201,  202, ...,  397,  398,  399],\n",
       "       [ 400,  401,  402, ...,  597,  598,  599],\n",
       "       ...,\n",
       "       [9400, 9401, 9402, ..., 9597, 9598, 9599],\n",
       "       [9600, 9601, 9602, ..., 9797, 9798, 9799],\n",
       "       [9800, 9801, 9802, ..., 9997, 9998, 9999]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_arr = cola_cupy.reshape(50,200)\n",
    "reshaped_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  201,  402,  603,  804, 1005, 1206, 1407, 1608, 1809, 2010,\n",
       "       2211, 2412, 2613, 2814, 3015, 3216, 3417, 3618, 3819, 4020, 4221,\n",
       "       4422, 4623, 4824, 5025, 5226, 5427, 5628, 5829, 6030, 6231, 6432,\n",
       "       6633, 6834, 7035, 7236, 7437, 7638, 7839, 8040, 8241, 8442, 8643,\n",
       "       8844, 9045, 9246, 9447, 9648, 9849])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_arr.diagonal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a CuPy Array to a cuDF DataFrame or Series\n",
    "\n",
    "We can also convert a CuPy `ndarray` to a cuDF `DataFrame` or `Series`, using the same `dlpack` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.7/site-packages/cudf-0.7.1+500.g24ab9736.dirty-py3.7-linux-x86_64.egg/cudf/io/dlpack.py:36: UserWarning: WARNING: cuDF from_dlpack() assumes column-major (Fortran order) input. If the input tensor is row-major, transpose it before passing it to this function.\n",
      "  res, valids = cpp_dlpack.from_dlpack(pycapsule_obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6 ...  199\n",
      "0  1  1  1  1  1  1  1 ...    1\n",
      "1  2  2  2  2  2  2  2 ...    2\n",
      "2  3  3  3  3  3  3  3 ...    3\n",
      "3  4  4  4  4  4  4  4 ...    4\n",
      "4  5  5  5  5  5  5  5 ...    5\n",
      "[192 more columns]\n"
     ]
    }
   ],
   "source": [
    "reshaped_df = cudf.from_dlpack(reshaped_arr.toDlpack())\n",
    "print(reshaped_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "5    5\n",
      "6    6\n",
      "7    7\n",
      "8    8\n",
      "9    9\n",
      "[40 more rows]\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.7/site-packages/cudf-0.7.1+500.g24ab9736.dirty-py3.7-linux-x86_64.egg/cudf/io/dlpack.py:36: UserWarning: WARNING: cuDF from_dlpack() assumes column-major (Fortran order) input. If the input tensor is row-major, transpose it before passing it to this function.\n",
      "  res, valids = cpp_dlpack.from_dlpack(pycapsule_obj)\n"
     ]
    }
   ],
   "source": [
    "print(cudf.from_dlpack(reshaped_arr.diagonal().toDlpack()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a cuDF DataFrame to a CuPy Sparse Matrix.\n",
    "\n",
    "We can also convert a `DataFrame` (or `Series`) to a CuPy sparse matrix. The sparse matrices data structure is defined by three dense arrays, which we can create from an existing cuDF `DataFrame` or `Series`. As this conversion is more involved, we define a helper function for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cudf_to_cupy_sparse(data, sparseformat='column'):\n",
    "    \"\"\"Converts a cuDF object to a CuPy sparse matrix.\n",
    "    \n",
    "    Note: Can't currently support DataFrames/Series with nulls\n",
    "    due to Boolean indexing issues\n",
    "    \"\"\"\n",
    "    if sparseformat not in ('row', 'column'):\n",
    "        raise NotImplementedError('Please choose between row or column format.')\n",
    "    \n",
    "    if isinstance(data, cudf.DataFrame):\n",
    "        nonzero_cols = [data[x][data[x] != 0] for x in data.columns]\n",
    "    elif isinstance(data, cudf.Series):\n",
    "        nonzero_cols = [data[data != 0]]\n",
    "    else:\n",
    "        raise TypeError('Please pass a cuDF object.')\n",
    "    \n",
    "    total_vals = sum([x.shape[0] for x in nonzero_cols])    \n",
    "    non_zero_vals = cudf.concat(nonzero_cols)\n",
    "    sparse_indices = cudf.concat([x.index for x in nonzero_cols])\n",
    "\n",
    "    dense_pointer_offsets = [0]\n",
    "    for i, col in enumerate(nonzero_cols):\n",
    "        dense_pointer_offsets.append(dense_pointer_offsets[i] + col.shape[0])\n",
    "\n",
    "    dense_pointer_offsets = cuda.to_device(dense_pointer_offsets)\n",
    "    \n",
    "    _matrix_constructor = cupy.sparse.csc_matrix\n",
    "    if sparseformat == 'row':\n",
    "        _matrix_constructor = cupy.sparse.csr_matrix\n",
    "        \n",
    "    out_arr = _matrix_constructor(\n",
    "        (cupy.asarray(non_zero_vals.data.mem),\n",
    "         cupy.asarray(sparse_indices.gpu_values),\n",
    "         cupy.asarray(dense_pointer_offsets)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return out_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a large, sparsely populated dataframe to illustrate this conversion to either sparse row or column matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame()\n",
    "nelem = 10000000\n",
    "nonzero = 5000\n",
    "for i in range(20):\n",
    "    arr = np.random.normal(5,5, nelem)\n",
    "    arr[np.random.choice(arr.shape[0], nelem-nonzero, replace=False)] = 0\n",
    "    df['a'+str(i)] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 464 ms, sys: 392 ms, total: 856 ms\n",
      "Wall time: 1.13 s\n",
      "CPU times: user 396 ms, sys: 424 ms, total: 820 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%time sparse_df = cudf_to_cupy_sparse(df, sparseformat='row')\n",
    "%time sparse_df = cudf_to_cupy_sparse(df, sparseformat='column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can continue our workflow with a CuPy sparse matrix. For example, let's say we wanted to get the sum of each column in the matrix. Because we're operating on sparse arrays (most of the values are 0) using a sparse matrix data structure, this operation is significantly faster (about 80-100x faster in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 7.11 ms\n",
      "CPU times: user 328 ms, sys: 268 ms, total: 596 ms\n",
      "Wall time: 593 ms\n"
     ]
    }
   ],
   "source": [
    "%time colsums = sparse_df.sum(axis=0)\n",
    "%time colsums = df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
